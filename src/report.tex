\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[margin=2.5cm]{geometry}
\usepackage{float}
\usepackage{cite}
\usepackage{url}
\usepackage{array}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage[pdfusetitle, colorlinks]{hyperref}
\hypersetup{
    colorlinks=true,    % Colores en lugar de cajas
    linkcolor=gray,
    citecolor=black, % Color de los enlaces internos
    filecolor=gray,  % Color de los enlaces a archivos
    urlcolor=gray       % Color de los enlaces externos
}
\usepackage{dcolumn}
\usepackage{bm}
\usepackage{appendix}
\usepackage{listings}
\lstset{
  language=Python,
  basicstyle=\ttfamily\small,
  commentstyle=\itshape\color{gray},
  keywordstyle=\bfseries\color{blue},
  numbers=left,
  numberstyle=\tiny\color{gray},
  stepnumber=1,
  numbersep=5pt,
  backgroundcolor=\color{white},
  frame=single,
  breaklines=true,
  breakatwhitespace=false,
  captionpos=b,
  tabsize=2,
  showspaces=false,
  showstringspaces=false
}

% Información del documento
\title{Simulación de Percolación en Redes 2D\\
       Análisis del Algoritmo de Hoshen-Kopelman}
\author{Mayorga , Gutierrez \& Vanegas\\
        Universidad Nacional de Colombia}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Este trabajo presenta una implementación computacional del proceso de percolación en redes bidimensionales utilizando el algoritmo de Hoshen-Kopelman. Se analizaron sistemas de diferentes tamaños ($L = 32, 64, 128, 256, 512$) para estudiar el comportamiento crítico cerca del umbral de percolación $p_c \approx 0.5927$. Los resultados muestran la formación de clusters percolantes y la dependencia del tamaño del sistema en las propiedades críticas.
\end{abstract}

\section{Introducción}

La teoría de la percolación constituye un pilar fundamental en la física estadística, ofreciendo un marco conceptual para describir la conectividad y la propagación de magnitudes a través de medios desordenados. Un aspecto central de la percolación es su capacidad para modelar transiciones de fase. Esta transición se manifiesta cuando la probabilidad de ocupación ($p$) de los elementos del medio alcanza un valor crítico específico, denominado umbral de percolación ($p_c$). Por debajo de este umbral, el sistema se caracteriza por la presencia de clústeres finitos y aislados, es decir, agrupaciones de elementos conectados que no logran atravesar el sistema en su totalidad. Sin embargo, al superar $p_c$, emerge un 'clúster infinito' o spanning cluster, una vasta red de elementos conectados que se extiende de un extremo a otro del sistema. Este cambio cualitativo en la conectividad es análogo a las transiciones de fase observadas en diversos sistemas físicos, como la magnetización o la condensación de gases. La percolación, al presentar este comportamiento crítico, se erige como un modelo universal para comprender fenómenos críticos en sistemas complejos, lo que confiere a su estudio una relevancia, incluso en configuraciones simplificadas como redes 2D \cite{CantabranaBarrio2018} \cite{PERCentralPercolation}.
\\

Para la percolación de sitios en una red cuadrada 2D, existe un valor de probabilidad crítica ($p_c$) que está bien establecido en la literatura. Si la probabilidad de ocupación $p$ es mayor que $p_c$, el sistema percola y se forma un clúster de gran tamaño que atraviesa la red. Por el contrario, si $p$ es menor que $p_c$, el sistema no percola y solo se observan clústeres pequeños y aislados. El valor aceptado para la probabilidad crítica de percolación de sitios en una red cuadrada 2D es aproximadamente 0.5927. Este valor, sin embargo, es específico para este tipo de red y dimensionalidad \cite{PERCentralPercolation}.
\\

Es fundamental reconocer que los valores teóricos de $p_c$
y las leyes de escalado asociadas se derivan bajo la suposición de sistemas de tamaño infinito. Sin embargo, las simulaciones computacionales se realizan inevitablemente en redes de tamaño finito. Para obtener una determinación rigurosa del umbral de percolación a partir de datos de simulación y para comprender cómo el comportamiento de un sistema finito se aproxima al límite (sistema infinito), es imprescindible aplicar técnicas de escalado de tamaño finito. Este enfoque permite analizar cómo las propiedades del sistema varían con el tamaño de la red y extrapolar el valor de $p_c$ para un sistema infinito, reconociendo que los sistemas finitos exhiben un 'ensanchamiento' del punto de transición en una región de transición. Así, las conclusiones obtenidas de una simulación bien diseñada deben involucrar un estudio sistemático a través de diferentes tamaños de sistema y la aplicación de estas técnicas para validar los resultados frente a las predicciones teóricas \cite{PERCentralPercolation}.

\section{Metodología}

\subsection{Algoritmo HK}
El algoritmo de Hoshen-Kopelman (HK), descrito originalmente por Joseph Hoshen y Raoul Kopelman en 1976 , es un método computacionalmente eficiente para identificar y etiquetar clústeres o componentes conectados en una cuadrícula o red. Su diseño está optimizado para minimizar el número de comparaciones necesarias, lo que lo hace particularmente adecuado para el análisis de fenómenos de percolación \cite{OntosightAINd}.

\begin{enumerate}[label=\textbf{\arabic*)}, ref=\arabic*)]
    \item \textbf{Inicialización del proceso}\\
    La función $hoshen\_kopelman$ recibe como entrada una matriz (matrix) que representa una cuadrícula, donde los valores (usualmente 0s y 1s) indican si un sitio está vacío u ocupado, respectivamente. También recibe el tamaño lateral de la cuadrícula, L. Se crea un vector labels del mismo tamaño que la matriz, inicializado con ceros, para almacenar las etiquetas de los clústeres; un 0 en labels significa que la celda está vacía o aún no ha sido etiquetada. Se inicializa una estructura UnionFind (uf) con un tamaño N+1 (siendo N = L*L), la cual es esencial para manejar la equivalencia entre las etiquetas de los clústeres. Finalmente, next\_label se establece en 1, marcando la primera etiqueta disponible para asignar a un nuevo clúster.
    
    \begin{enumerate}[label=\textbf{\roman*)}, ref=\roman*)]
        \item \textbf{Estructura Union-Find:} La estructura UnionFind es fundamental para la eficiencia del algoritmo, permitiendo la gestión de conjuntos disjuntos. Se compone de un vector parent, donde parent[i] almacena el padre del elemento i; inicialmente, cada elemento es su propio padre. El método find(x) localiza la $''$raíz$''$ del conjunto al que pertenece x, optimizando las búsquedas futuras mediante la compresión de caminos, lo que hace que los nodos apunten directamente a la raíz. El método unite(x,y) fusiona los conjuntos que contienen a x e y. Para ello, encuentra las raíces de x e y, y si estas son diferentes, establece la raíz de uno como padre de la raíz del otro, logrando así la unión de los dos conjuntos.
    \end{enumerate}
    \item \textbf{Etiquetado preliminar (Primera pasada)}\\
    El algoritmo recorre cada celda de la matriz. Para cada celda (i, j) que se encuentra $"$ocupada" (es decir, matrix[id] == 1), se examinan sus vecinos adyacentes: "norte" (up) y $"$oeste" (left). Si ambos vecinos están vacíos o no ocupados, se le asigna una nueva etiqueta a la celda actual (labels[id] = next\_label++). Si solo el vecino Norte está ocupado, la celda actual hereda la etiqueta de su vecino Norte (labels[id] = up). De manera similar, si solo el vecino Oeste está ocupado, la celda actual recibe la etiqueta de su vecino Oeste (labels[id] = left). Cuando ambos vecinos (Norte y Oeste) están ocupados, la celda actual se etiqueta con la menor de las dos etiquetas de sus vecinos (labels[id] = std::min(up, left)). Además, se utiliza la estructura UnionFind para unir las dos etiquetas (uf.unite(up, left)), indicando que pertenecen al mismo clúster. Esta unión es crítica porque permite reconocer que dos etiquetas inicialmente distintas forman parte de un mismo clúster.
    \item \textbf{Compactación de etiquetas (Segunda Pasada)}\\
    Después de la primera pasada, es posible que algunas celdas tengan etiquetas diferentes pero pertenezcan al mismo clúster debido a las uniones realizadas por UnionFind. Esta etapa se encarga de $"$compactar$"$ esas etiquetas, asegurando que todos los miembros de un mismo clúster compartan una única etiqueta unificada. Para esto, se emplean dos (unordered\_map): root\_to\_compact, que relaciona la $"$raíz" de un clúster (obtenida mediante UnionFind::find()) con una etiqueta compactada y consecutiva, y cluster\_sizes, que almacena el tamaño de cada clúster utilizando estas etiquetas compactadas. El algoritmo itera sobre todas las celdas en labels. Para cada celda que ya ha sido etiquetada (es decir, no es cero), se busca la raíz de su etiqueta utilizando uf.find(labels[i]). Si esta raíz aún no ha sido mapeada a una etiqueta compactada, se le asigna una nueva (compact\_label++). Posteriormente, la etiqueta de la celda actual se actualiza a su etiqueta compactada (labels[i] = label), y el tamaño del clúster correspondiente en cluster\_sizes[label] se incrementa.
    \item \textbf{Detección de percolación}\\
    La percolación es un fenómeno que ocurre cuando un clúster logra conectar lados opuestos de la matriz. Para identificar esto, se crean cuatro conjuntos desordenados (unordered\_set) que almacenan las etiquetas de los clústeres que tocan cada uno de los cuatro bordes de la matriz: top (fila superior), bottom (fila inferior), left (columna izquierda), y right (columna derecha). Se recorren las celdas de estas filas y columnas específicas, insertando las etiquetas de las celdas ocupadas en sus respectivos conjuntos.
\\

Para la percolación vertical, se verifica si alguna etiqueta está presente tanto en el conjunto top como en el conjunto bottom. Si se encuentra una etiqueta común, indica la existencia de un clúster que conecta la parte superior e inferior de la matriz. De manera similar, para la percolación horizontal, se comprueba si alguna etiqueta existe tanto en el conjunto left como en el conjunto right. Si es así, significa que un clúster conecta el lado izquierdo con el derecho de la matriz. Un conjunto percolating\_labels almacena las etiquetas de los clústeres que percolan (ya sea vertical u horizontalmente). La variable booleana percolates indica si se ha detectado al menos un clúster percolante. Finalmente, se calcula max\_cluster\_size entre todos los clústeres que percolan.
    \item \textbf{Conclusión del algoritmo}\\
    La función concluye devolviendo una estructura ClusterInfo. Esta estructura encapsula los resultados clave del análisis, que incluyen: cluster\_sizes (un mapa que asocia las etiquetas compactadas con sus respectivos tamaños de clúster), percolates (un valor booleano que indica si se produjo percolación), max\_cluster\_size (el tamaño del clúster percolante más grande), y labels (el vector final de etiquetas compactadas asignadas a cada celda de la matriz).
\end{enumerate}

\subsection{Código para gráficar}


\subsection{Script de bash}

El script de Bash automatiza la ejecución de simulaciones de percolación para distintos tamaños de red y probabilidades, utilizando un programa ejecutable llamado main.x. Al iniciar, elimina cualquier carpeta de resultados previa y crea una nueva estructura de directorios para almacenar datos crudos, archivos auxiliares y gráficos. Luego, define una lista de tamaños de red L que serán evaluados y genera todas las combinaciones posibles con los valores de probabilidad listados en el archivo probabilidades50.txt. Estas combinaciones se almacenan en un archivo temporal para su procesamiento posterior.\\
 \\
El núcleo del script es una función llamada simulate, que toma como entrada un valor de L y una probabilidad p. Para cada combinación, ejecuta 10 bloques de 10 repeticiones del programa principal, recolectando el tamaño del mayor clúster percolante y si ocurrió o no percolación en cada ejecución. Con esta información, calcula el valor medio de la probabilidad de percolación P y el tamaño promedio del clúster percolante (normalizado respecto al área de la red), junto con sus respectivas desviaciones estándar. Los resultados se guardan en archivos individuales para cada combinación y también se imprimen en formato csv como una línea resumen.\\
\\
El script utiliza GNU parallel para ejecutar múltiples simulaciones de forma concurrente, acelerando considerablemente el proceso. Una vez completadas todas las combinaciones, se genera un archivo resumen.csv que contiene los resultados ordenados por tamaño de red y probabilidad. Finalmente, se limpian los archivos temporales utilizados durante la ejecución y se ordenan los archivos de resultados finales para facilitar su análisis posterior
\subsection{Automatización por medio de Makefile}

\section{Resultados}

Mediante el código descrito anteriormente, se exploró el comportamiento de la percolación en una matriz bidimensional.

\section{Conclusiones}

\clearpage

\bibliographystyle{plain}
\bibliography{report1}

\end{document}